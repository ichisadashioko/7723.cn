{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [],
			"source": [
				"# input: url string\n",
				"# output: bytes"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 13,
			"metadata": {},
			"outputs": [],
			"source": [
				"import os\n",
				"import time\n",
				"import pickle\n",
				"import collections\n",
				"import gzip\n",
				"\n",
				"import tqdm"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"20001503"
						]
					},
					"execution_count": 3,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"hash_log_filepath = 'tmp_pickle_files/hash_log-1650109654532523300.pickle'\n",
				"os.path.getsize(hash_log_filepath)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"<class 'list'>\n"
					]
				}
			],
			"source": [
				"with open(hash_log_filepath, mode='rb') as infile:\n",
				"    hash_log = pickle.load(infile)\n",
				"    print(type(hash_log))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"195094"
						]
					},
					"execution_count": 6,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"len(hash_log)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"{'path': '.requests_cache\\\\00\\\\000000a86ac9fd0cc77dc4ecf80f0b89',\n",
							" 'size': 132302,\n",
							" 'md5hash': b\"\\t\\xf9V!W\\x82\\xbcIt/\\xcc\\x8c'k\\x1f\\xe1\"}"
						]
					},
					"execution_count": 5,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"hash_log[0]"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# store unique content by md5 hash and size"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 9,
			"metadata": {},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"100%|██████████| 195094/195094 [00:00<00:00, 305485.96it/s]\n"
					]
				},
				{
					"data": {
						"text/plain": [
							"133089"
						]
					},
					"execution_count": 9,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"# key: (md5, size)\n",
				"# value: list of old url md5 hash filepath\n",
				"\n",
				"new_cache_structure_content_dict = collections.defaultdict(list)\n",
				"\n",
				"invalid_hash_log_entries = []\n",
				"\n",
				"for hash_log_entry in tqdm.tqdm(hash_log):\n",
				"    if not isinstance(hash_log_entry, dict):\n",
				"        invalid_hash_log_entries.append(hash_log_entry)\n",
				"        continue\n",
				"\n",
				"    if 'path' not in hash_log_entry:\n",
				"        invalid_hash_log_entries.append(hash_log_entry)\n",
				"        continue\n",
				"\n",
				"    if 'size' not in hash_log_entry:\n",
				"        invalid_hash_log_entries.append(hash_log_entry)\n",
				"        continue\n",
				"\n",
				"    if 'md5hash' not in hash_log_entry:\n",
				"        invalid_hash_log_entries.append(hash_log_entry)\n",
				"        continue\n",
				"\n",
				"    new_cache_structure_content_dict[(hash_log_entry['md5hash'], hash_log_entry['size'])].append(hash_log_entry['path'])\n",
				"\n",
				"key_list = list(new_cache_structure_content_dict.keys())\n",
				"len(key_list)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 12,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"new_cache_structure_content_dict-1653545293.578412.pickle\n"
					]
				}
			],
			"source": [
				"new_cache_structure_content_dict_log_filepath = f'new_cache_structure_content_dict-{time.time()}.pickle'\n",
				"print(new_cache_structure_content_dict_log_filepath)\n",
				"\n",
				"with open(new_cache_structure_content_dict_log_filepath, mode='wb') as outfile:\n",
				"    pickle.dump(new_cache_structure_content_dict, outfile)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"0"
						]
					},
					"execution_count": 10,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"len(invalid_hash_log_entries)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## copy the body content to another directory"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 14,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"(b\"\\t\\xf9V!W\\x82\\xbcIt/\\xcc\\x8c'k\\x1f\\xe1\", 132302)"
						]
					},
					"execution_count": 14,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"key_list[0]"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 16,
			"metadata": {},
			"outputs": [],
			"source": [
				"body_content_root_dir = 'd:\\htmlbodycontentcache'\n",
				"if not os.path.exists(body_content_root_dir):\n",
				"    os.makedirs(body_content_root_dir)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 18,
			"metadata": {},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"9fb27cab19d68f8a63f632cc0475ef9c-802344.gzip: 100%|██████████| 133089/133089 [1:46:55<00:00, 20.74it/s]     \n"
					]
				}
			],
			"source": [
				"deleted_cache_files = []\n",
				"\n",
				"pbar = tqdm.tqdm(key_list)\n",
				"for key in pbar:\n",
				"    if os.path.exists('stop'):\n",
				"        break\n",
				"\n",
				"    cache_filepath_list = new_cache_structure_content_dict[key]\n",
				"    md5hash_bs, size = key\n",
				"\n",
				"    if size == 0:\n",
				"        continue\n",
				"\n",
				"    md5hash_str = md5hash_bs.hex()\n",
				"    new_cache_filename = f'{md5hash_str}-{size}.gzip'\n",
				"    new_cache_filepath = os.path.join(body_content_root_dir, new_cache_filename)\n",
				"    if os.path.exists(new_cache_filepath):\n",
				"        continue\n",
				"\n",
				"    pbar.set_description(new_cache_filename)\n",
				"\n",
				"    for old_cache_filepath in cache_filepath_list:\n",
				"        if not os.path.exists(old_cache_filepath):\n",
				"            deleted_cache_files.append(old_cache_filepath)\n",
				"            continue\n",
				"\n",
				"        with gzip.open(new_cache_filepath, mode='wb') as outfile:\n",
				"            with open(old_cache_filepath, mode='rb') as infile:\n",
				"                content_bs = infile.read()\n",
				"                outfile.write(content_bs)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# old code"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"url_info_list_filepath = 'tmp_pickle_files/url_info_list-1650285069904349100'\n",
				"os.path.getsize(url_info_list_filepath)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"with open(url_info_list_filepath, mode='rb') as infile:\n",
				"    url_info_list = pickle.load(infile)\n",
				"    print(type(url_info_list))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"len(url_info_list)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"url_info_list[0]"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import tqdm"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"number_of_url_info = len(url_info_list)\n",
				"number_of_url_info"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"for index in tqdm.tqdm(range(number_of_url_info)):\n",
				"    url_info = url_info_list[index]\n",
				"    if 'response_size' not in url_info:\n",
				"        print(index)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"for url_info in tqdm.tqdm(url_info_list):\n",
				"    response_size = url_info['response_size']\n",
				"    cache_path = url_info['cache_path']\n",
				"    if response_size == 0:\n",
				"        os.remove(cache_path)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import traceback"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"for index in tqdm.tqdm(range(number_of_url_info)):\n",
				"    url_info = url_info_list[index]\n",
				"    try:\n",
				"        response_size = url_info['response_size']\n",
				"        cache_path = url_info['cache_path']\n",
				"        if response_size == 0:\n",
				"            if os.path.exists(cache_path):\n",
				"                os.remove(cache_path)\n",
				"    except Exception as ex:\n",
				"        stack_trace_str = traceback.format_exc()\n",
				"        print(stack_trace_str)\n",
				"        print(index)\n",
				"        print(url_info)\n",
				"        print(ex)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"url_info_list[9158]"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"os.path.exists('.requests_cache\\\\fc\\\\fc2cabf6e440dcc364991de186d76067')"
			]
		}
	],
	"metadata": {
		"interpreter": {
			"hash": "0a529d3509ce381a2ce9157bc78b598ed11ef7a775448a20f9c3074147cbb316"
		},
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
