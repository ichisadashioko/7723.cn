{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import time\n",
				"import re\n",
				"import os\n",
				"import json\n",
				"from urllib.parse import urlparse, urlunparse, urljoin\n",
				"from pprint import pprint\n",
				"import pickle\n",
				"\n",
				"# external modules\n",
				"from tqdm import tqdm\n",
				"import requests\n",
				"from bs4 import BeautifulSoup\n",
				"\n",
				"# local modules\n",
				"from shared import *"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Crawl all the entry urls from multiple pages from a game genre page."
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"We find the `last page` button to parse the number of page for that game genre.\n",
				"\n",
				"![](./docs/images/7723.cn-game-listing-last-page.png)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def get_all_genre_urls(url: str):\n",
				"    content, response, error = GET(url)\n",
				"    \n",
				"    if content is None:\n",
				"        return None\n",
				"    \n",
				"    _, content = Encoding.decode(content)\n",
				"    soup = BeautifulSoup(content)\n",
				"    selector = '.pagenation'\n",
				"    page_container = soup.select_one(selector)\n",
				"    \n",
				"    if page_container is None:\n",
				"        print(f'Failed to select {selector} for getting pages container!')\n",
				"        print('->', url)\n",
				"        return None\n",
				"    \n",
				"    selector = 'a'\n",
				"    els = page_container.select(selector)\n",
				"    \n",
				"    if len(els) == 0:\n",
				"        print(f'Failed to select {selector} for page navigation anchors!')\n",
				"        print('->', url)\n",
				"        return None\n",
				"    \n",
				"    last_page_anchor = els[-1]\n",
				"    if not 'href' in last_page_anchor.attrs:\n",
				"        print(f'The last anchor element does not have href attribute!')\n",
				"        print('->', url)\n",
				"        return None\n",
				"\n",
				"    last_page_url = last_page_anchor.attrs['href']\n",
				"    genre_base, last_page_doc_name = os.path.split(last_page_url)\n",
				"    \n",
				"    num_sr = re.search(r'\\d+', last_page_doc_name)\n",
				"    if num_sr is None:\n",
				"        print(f'Failed to find number of pages!')\n",
				"        print('->', url)\n",
				"        return None\n",
				"    \n",
				"    num_text = last_page_doc_name[num_sr.start():num_sr.end()]\n",
				"    num_pages = int(num_text)\n",
				"    \n",
				"    genre_page_urls = []\n",
				"\n",
				"    for i in range(num_pages):\n",
				"        page_url = f'{genre_base}/{last_page_doc_name[:num_sr.start()]}{i+1}{last_page_doc_name[num_sr.end():]}'\n",
				"        genre_page_urls.append(page_url)\n",
				"\n",
				"    return genre_page_urls"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"![](./docs/images/7723.cn-symbian-hp.png)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"genre_first_page_urls = [\n",
				"    'http://www.7723.cn/zuixin/jiaose_1.htm', # 角色扮演 # RPG\n",
				"    'http://www.7723.cn/zuixin/yizhi_1.htm', # 益智游戏 # Puzzle games\n",
				"    'http://www.7723.cn/zuixin/dongzuo_1.htm', # 动作游戏 # Action games\n",
				"    'http://www.7723.cn/zuixin/saiche_1.htm', # 赛车游戏 # Racing games\n",
				"    'http://www.7723.cn/zuixin/maoxian_1.htm', # 冒险游戏 # Adventure games\n",
				"    'http://www.7723.cn/zuixin/yangcheng_1.htm', # 养成游戏 # Dating sim?\n",
				"    'http://www.7723.cn/zuixin/tiyu_1.htm', # 体育游戏 # Sports games\n",
				"    'http://www.7723.cn/zuixin/gedou_1.htm', # 格斗游戏 # Fighting games\n",
				"    'http://www.7723.cn/zuixin/qipai_1.htm', # 棋牌游戏 # Board games\n",
				"    'http://www.7723.cn/zuixin/celue_1.htm', # 策略游戏 # Strategy games\n",
				"    'http://www.7723.cn/zuixin/sheji_1.htm', # 射击游戏 # Shooting games\n",
				"    'http://www.7723.cn/zuixin/moni_1.htm', # 模拟经营 # Simulation (city building, shop management, etc.)\n",
				"    'http://www.7723.cn/zuixin/feixing_1.htm', # 飞行游戏 # Flying (e.g. space ship) games\n",
				"    'http://www.7723.cn/zuixin/wangyou_1.htm', # 手机网游 # online games\n",
				"]"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# for url in genre_first_page_urls:\n",
				"#     url_hash = hash_url(url)\n",
				"#     cache_file, sub_cache_dir = get_hash_file_location(url_hash)\n",
				"\n",
				"#     print(os.path.exists(cache_file), cache_file)\n",
				"#     if os.path.exists(cache_file):\n",
				"#         content = open(cache_file, mode='rb').read()\n",
				"#         print(type(content), len(content))\n",
				"        \n",
				"#         encoding, decoded_content = Encoding.decode(content)\n",
				"#         print(encoding, type(decoded_content), len(decoded_content))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"scrolled": false
			},
			"outputs": [],
			"source": [
				"game_listing_pages = []\n",
				"\n",
				"for first_page_url in genre_first_page_urls:\n",
				"    genre_page_urls = get_all_genre_urls(first_page_url)\n",
				"    \n",
				"    if genre_page_urls is None:\n",
				"        continue\n",
				"\n",
				"    print(len(genre_page_urls), first_page_url)\n",
				"    \n",
				"    game_listing_pages.extend(genre_page_urls)\n",
				"\n",
				"len(game_listing_pages), len(set(game_listing_pages))"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"request and cache response for these pages"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# pbar = tqdm(game_listing_pages)\n",
				"# for page_url in pbar:\n",
				"#     pbar.set_description(page_url)\n",
				"#     GET(page_url, verbose=False)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Parse game listing page for game page url"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Here is the sample of game listing page.\n",
				"\n",
				"![](./docs/images/7723.cn-game-listing-page.png)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def parse_game_listing_page(url: str, verbose=True):\n",
				"    content, response, error = GET(url, verbose=verbose)\n",
				"    if content is None:\n",
				"        if verbose:\n",
				"            print('content is None!')\n",
				"        return None\n",
				"    \n",
				"    _, decoded_content = Encoding.decode(content)\n",
				"    soup = BeautifulSoup(decoded_content)\n",
				"    \n",
				"    selector = '#content'\n",
				"    content_div = soup.select_one(selector)\n",
				"    if content_div is None:\n",
				"        print(f'Failed to get content container with selector {selector}')\n",
				"        print('->', url)\n",
				"        return None\n",
				"    \n",
				"    selector = 'ul.container'\n",
				"    ul_container = content_div.select_one(selector)\n",
				"    if ul_container is None:\n",
				"        print(f'Failed to get game list container with selector {selector}')\n",
				"        print('->', url)\n",
				"        return None\n",
				"    \n",
				"    game_pages = []\n",
				"\n",
				"    els = ul_container.find_all('li', recursive=False)\n",
				"    els.extend(ul_container.select('dd>li'))\n",
				"\n",
				"    for el in els:\n",
				"        selector = 'a'\n",
				"        anchor = el.select_one(selector)\n",
				"        if anchor is None:\n",
				"            print(f'This game entry does not have an a element!')\n",
				"            print('->', el)\n",
				"            print('->', url)\n",
				"            continue\n",
				"            \n",
				"        if 'href' in anchor.attrs:\n",
				"            game_page_url = anchor.attrs['href']\n",
				"            game_pages.append(game_page_url)\n",
				"    \n",
				"    return game_pages"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"scrolled": true
			},
			"outputs": [],
			"source": [
				"game_pages = []\n",
				"\n",
				"pbar = tqdm(game_listing_pages)\n",
				"for url in pbar:\n",
				"    pbar.set_description(url)\n",
				"    \n",
				"    _game_pages = parse_game_listing_page(url, verbose=True)\n",
				"    \n",
				"    if _game_pages is None:\n",
				"        print(f'There is some problem with this page!')\n",
				"        print('->', url)\n",
				"        print('='*32)\n",
				"    else:\n",
				"        game_pages.extend(_game_pages)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"scrolled": true
			},
			"outputs": [],
			"source": [
				"len(game_pages), len(set(game_pages))"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"cache request response while we are doing other things"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"scrolled": false
			},
			"outputs": [],
			"source": [
				"# pbar = tqdm(game_pages)\n",
				"# for url in pbar:\n",
				"#     pbar.set_description(url)\n",
				"#     GET(url, verbose=False)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Parse game page for title and download link for multiple versions"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Sample game page\n",
				"\n",
				"![]()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def parse_game_entry_url(url: str, verbose=True):\n",
				"    content, response, error = GET(url, verbose=verbose)\n",
				"    \n",
				"    if content is None:\n",
				"        print('Please check error from global variables!')\n",
				"        return None\n",
				"    \n",
				"    _, content = Encoding.decode(content)\n",
				"    soup = BeautifulSoup(content)\n",
				"    \n",
				"    selector = '#content'\n",
				"    content_div = soup.select_one(selector)\n",
				"    if content_div is None:\n",
				"        print(f'Format for this page is not compatible! There is no element matches {selector}!')\n",
				"        print('->', url)\n",
				"        return None\n",
				"    \n",
				"    # retrieve game title\n",
				"    title = None\n",
				"    selector = '.title'\n",
				"    title_div = content_div.select_one(selector)\n",
				"    if title_div is None:\n",
				"        print(f'Cannot find title! There is no element matches {selector}!')\n",
				"        print('->', url)\n",
				"    else:\n",
				"        selector = 'h3'\n",
				"        title_heading = title_div.select_one(selector)\n",
				"        if title_heading is None:\n",
				"            print(f'Cannot find title! There is no element matches {selector}!')\n",
				"            print('->', url)\n",
				"        else:\n",
				"            title = title_heading.text\n",
				"    \n",
				"    selector = 'ul.container'\n",
				"    ul_containers = content_div.select('ul.container')\n",
				"    if not (len(ul_containers) == 3):\n",
				"        print(f'Format for this page is not compatible! Number of elements match {selector} is not supported!')\n",
				"        print('->', url)\n",
				"        return None\n",
				"\n",
				"    # retrieve game banner\n",
				"    banner_url = None\n",
				"    selector = 'img'\n",
				"    banner_img = ul_containers[0].select_one(selector)\n",
				"    if banner_img is None:\n",
				"        print(f'Failed to get game banner with selector {selector}!')\n",
				"        print('->', url)\n",
				"    else:\n",
				"        if 'src' in banner_img.attrs:\n",
				"            banner_url = banner_img.attrs['src']\n",
				"        else:\n",
				"            print(f'Failed to get game banner. The img element does not contain src attribute!')\n",
				"            print('->', url)\n",
				"    \n",
				"    # retrieve sample gameplay images\n",
				"    sample_gameplay_image_urls = [imgE.attrs['src'] for imgE in ul_containers[1].select('img')]\n",
				"    \n",
				"    # retrieve game binaries for multiple phone models\n",
				"    versions = []\n",
				"    li_containers = ul_containers[2].select('li')\n",
				"    versions = []\n",
				"    for li_container in li_containers:\n",
				"        selector = 'a'\n",
				"        anchor_element = li_container.select_one(selector)\n",
				"        if anchor_element is None:\n",
				"            print(f'Failed to select anchor with {selector}!')\n",
				"            print('->', url)\n",
				"            print('->', li_container)\n",
				"            continue\n",
				"        \n",
				"        if not 'href' in anchor_element.attrs:\n",
				"            print(f'Failed to retrieve download url. Element does not have href attribute.')\n",
				"            print('->', url)\n",
				"            print(anchor_element)\n",
				"            continue\n",
				"            \n",
				"        # send a post request to download the game\n",
				"        version_url  = anchor_element.attrs['href']\n",
				"        \n",
				"        version_resolution = None\n",
				"        version_model = None\n",
				"        version_desc = None\n",
				"        \n",
				"        selector = 'p'\n",
				"        version_desc_el = li_container.select_one(selector)\n",
				"        if version_desc_el is None:\n",
				"            print(f'Failed to retrieve game version description with {selector} selector!')\n",
				"            print('->', url)\n",
				"        else:\n",
				"            version_desc = version_desc_el.text\n",
				"            resolution_sr = re.search(r'\\((\\d+)×(\\d+)\\)', version_desc)\n",
				"            \n",
				"            if resolution_sr is None:\n",
				"                print(f'Failed to search for this game version screen resolution in description!')\n",
				"                print('->', url)\n",
				"                print('->', version_desc)\n",
				"            else:\n",
				"                version_resolution = version_desc[resolution_sr.start():resolution_sr.end()]\n",
				"                version_resolution = version_resolution.replace('×', 'x')\n",
				"                version_resolution = re.sub(r'[\\(\\)]+', '', version_resolution)\n",
				"                \n",
				"                model_sr = re.search(r'[\\x00-\\x7F]+', version_desc[:resolution_sr.start()])\n",
				"                \n",
				"                if model_sr is None:\n",
				"                    if '触摸屏通用版' in version_desc:\n",
				"                        # universal touch screen phone models\n",
				"                        version_model = 'touch'\n",
				"                    elif '屏通用版' in version_desc:\n",
				"                        # universal phone models\n",
				"                        version_model = 'universal'\n",
				"                    else:\n",
				"                        print(f'Failed to search for supported model in description!')\n",
				"                        print('->', url)\n",
				"                        print('->', version_desc)\n",
				"                else:\n",
				"                    version_model = version_desc[model_sr.start():model_sr.end()]\n",
				"                    version_model = version_model.replace(' ', '')\n",
				"\n",
				"        versions.append(GameVersion(\n",
				"            url=version_url,\n",
				"            resolution=version_resolution,\n",
				"            model=version_model,\n",
				"            description=version_desc,\n",
				"        ))\n",
				"    \n",
				"    return GameEntry(\n",
				"        url=url,\n",
				"        title=title,\n",
				"        banner_url=banner_url,\n",
				"        sample_gameplay_image_urls=sample_gameplay_image_urls,\n",
				"        versions=versions,\n",
				"    )"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"scrolled": true
			},
			"outputs": [],
			"source": [
				"game_entries = []\n",
				"pbar = tqdm(game_pages)\n",
				"for url in pbar:\n",
				"    pbar.set_description(f'Parsing {url}')\n",
				"    \n",
				"    game_entry = parse_game_entry_url(url, verbose=False)\n",
				"    \n",
				"    if game_entry is None:\n",
				"        continue\n",
				"    \n",
				"    game_entries.append(game_entry)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"serialized_game_entries = pickle.dumps(game_entries)\n",
				"type(serialized_game_entries)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"filename = 'game_entries.pickle'\n",
				"# with open(filename, mode='wb') as stream:\n",
				"#     stream.write(serialized_game_entries)\n",
				"\n",
				"game_entries = pickle.loads(open(filename, mode='rb').read())"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"game_entries"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"pbar = tqdm(game_entries)\n",
				"\n",
				"url_list = []\n",
				"\n",
				"for game_entry in pbar:\n",
				"    if game_entry.banner_url is not None:\n",
				"        url_list.append(game_entry.banner_url)\n",
				"#         pbar.set_description(f'{game_entry.url} - {game_entry.banner_url}')\n",
				"#         GET(game_entry.banner_url, verbose=False)\n",
				"\n",
				"    for img_url in game_entry.sample_gameplay_image_urls:\n",
				"        url_list.append(img_url)\n",
				"#         pbar.set_description(f'{game_entry.url} - {img_url}')\n",
				"#         GET(img_url, verbose=False)\n",
				"    \n",
				"    for game_version in game_entry.versions:\n",
				"        url_list.append(game_version.url)\n",
				"#         pbar.set_description(f'{game_entry.url} - {game_version.url}')\n",
				"#         POST(game_version.url, verbose=False)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"len(url_list)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"url_set = set(url_list)\n",
				"len(url_set)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"url_hashes_list = [hash_url(url) for url in url_list]\n",
				"len(url_hashes_list)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"url_hashes_set = set(url_hashes_list)\n",
				"len(url_hashes_set)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"url_list = list(url_set)\n",
				"len(url_list)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"pbar = tqdm(url_list)\n",
				"\n",
				"not_cached_url_list = []\n",
				"for url in pbar:\n",
				"    url_hash = hash_url(url)\n",
				"    cache_file, sub_cache_dir = get_hash_file_location(url_hash)\n",
				"    \n",
				"    if not os.path.exists(cache_file):\n",
				"        not_cached_url_list.append(url)\n",
				"\n",
				"len(not_cached_url_list)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"not_cached_url_list"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# All if these urls are unreachable\n",
				"# for url in not_cached_url_list:\n",
				"#     url_hash = hash_url(url)\n",
				"#     cache_file, sub_cache_dir = get_hash_file_location(url_hash)\n",
				"    \n",
				"#     open(cache_file, mode='wb').close()\n",
				"#     print(os.path.exists(cache_file), cache_file)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# split the url list into multiple list for using with other program to request them\n",
				"import numpy as np\n",
				"\n",
				"num_parts = 50\n",
				"sub_url_lists = np.array_split(np.array(url_list), num_parts)\n",
				"len(sub_url_lists)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"scrolled": true
			},
			"outputs": [],
			"source": [
				"basename = 'url_list_part_'\n",
				"\n",
				"for i in range(num_parts):\n",
				"    print(i, len(sub_url_lists[i]))\n",
				"    \n",
				"    filename = basename + repr(i).zfill(len(repr(num_parts)))\n",
				"    print(filename)\n",
				"    \n",
				"    with open(filename, mode='w', encoding='utf-8') as stream:\n",
				"        json.dump(sub_url_lists[i].tolist(), stream, indent=2)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"scrolled": true
			},
			"outputs": [],
			"source": [
				"# CAUTION: this code might take a few days to complete\n",
				"# pbar = tqdm(url_list)\n",
				"\n",
				"# for url in pbar:\n",
				"#     pbar.set_description(url)\n",
				"#     GET(url, verbose=False)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"sample_game_urls = [\n",
				"    'http://www.7723.cn/download/10172.htm', # 战姬无双-花缭乱\n",
				"    'http://www.7723.cn/download/8077.htm', # 苍穹默示录完美运行版\n",
				"    'http://www.7723.cn/download/10420.htm', # 苍弓默示录－吞噬时空    \n",
				"]"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"entry_url = 'http://www.7723.cn/download/8077.htm'\n",
				"entry = parse_game_entry_url(entry_url)\n",
				"entry"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
